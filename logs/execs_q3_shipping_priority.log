Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132031_1333483535.txt
OK
Time taken: 3.409 seconds
OK
Time taken: 0.095 seconds
OK
Time taken: 0.067 seconds
OK
Time taken: 0.009 seconds
OK
Time taken: 0.233 seconds
OK
Time taken: 0.033 seconds
OK
Time taken: 0.034 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 23 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:1761)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:1735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.mkdirs(NameNode.java:542)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132032_859462454.txt
OK
Time taken: 3.819 seconds
OK
Time taken: 0.096 seconds
OK
Time taken: 0.066 seconds
OK
Time taken: 0.01 seconds
OK
Time taken: 0.3 seconds
OK
Time taken: 0.048 seconds
OK
Time taken: 0.034 seconds
OK
Time taken: 0.041 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132031_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132031_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132031_0001
2016-04-13 20:32:10,209 Stage-1 map = 0%,  reduce = 0%
2016-04-13 20:32:19,277 Stage-1 map = 5%,  reduce = 0%
2016-04-13 20:32:22,303 Stage-1 map = 8%,  reduce = 0%
2016-04-13 20:32:25,328 Stage-1 map = 26%,  reduce = 0%
2016-04-13 20:32:28,351 Stage-1 map = 47%,  reduce = 0%
2016-04-13 20:32:31,386 Stage-1 map = 62%,  reduce = 0%
2016-04-13 20:32:34,420 Stage-1 map = 67%,  reduce = 0%
2016-04-13 20:32:37,453 Stage-1 map = 70%,  reduce = 0%
2016-04-13 20:32:40,487 Stage-1 map = 79%,  reduce = 7%
2016-04-13 20:32:43,520 Stage-1 map = 88%,  reduce = 7%
2016-04-13 20:32:46,554 Stage-1 map = 94%,  reduce = 13%
2016-04-13 20:32:49,588 Stage-1 map = 99%,  reduce = 13%
2016-04-13 20:32:52,624 Stage-1 map = 100%,  reduce = 13%
2016-04-13 20:32:58,688 Stage-1 map = 100%,  reduce = 40%
2016-04-13 20:33:00,716 Stage-1 map = 100%,  reduce = 83%
2016-04-13 20:33:01,735 Stage-1 map = 100%,  reduce = 94%
2016-04-13 20:33:03,764 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132031_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132031_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132031_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132031_0002
2016-04-13 20:33:12,960 Stage-2 map = 0%,  reduce = 0%
2016-04-13 20:33:22,016 Stage-2 map = 7%,  reduce = 0%
2016-04-13 20:33:25,036 Stage-2 map = 13%,  reduce = 0%
2016-04-13 20:33:28,059 Stage-2 map = 17%,  reduce = 0%
2016-04-13 20:33:31,088 Stage-2 map = 19%,  reduce = 0%
2016-04-13 20:33:34,116 Stage-2 map = 20%,  reduce = 0%
2016-04-13 20:33:37,143 Stage-2 map = 21%,  reduce = 0%
2016-04-13 20:33:40,171 Stage-2 map = 22%,  reduce = 1%
2016-04-13 20:33:43,202 Stage-2 map = 24%,  reduce = 2%
2016-04-13 20:33:46,230 Stage-2 map = 26%,  reduce = 2%
2016-04-13 20:33:49,257 Stage-2 map = 29%,  reduce = 3%
2016-04-13 20:33:52,285 Stage-2 map = 30%,  reduce = 3%
2016-04-13 20:33:55,314 Stage-2 map = 33%,  reduce = 3%
2016-04-13 20:33:58,343 Stage-2 map = 35%,  reduce = 3%
2016-04-13 20:34:01,371 Stage-2 map = 37%,  reduce = 3%
2016-04-13 20:34:04,400 Stage-2 map = 39%,  reduce = 4%
2016-04-13 20:34:07,428 Stage-2 map = 41%,  reduce = 4%
2016-04-13 20:34:10,457 Stage-2 map = 43%,  reduce = 4%
2016-04-13 20:34:13,484 Stage-2 map = 44%,  reduce = 4%
2016-04-13 20:34:16,513 Stage-2 map = 45%,  reduce = 5%
2016-04-13 20:34:19,541 Stage-2 map = 47%,  reduce = 6%
2016-04-13 20:34:22,568 Stage-2 map = 49%,  reduce = 6%
2016-04-13 20:34:25,592 Stage-2 map = 51%,  reduce = 6%
2016-04-13 20:34:28,616 Stage-2 map = 53%,  reduce = 7%
2016-04-13 20:34:31,640 Stage-2 map = 55%,  reduce = 7%
2016-04-13 20:34:34,665 Stage-2 map = 57%,  reduce = 7%
2016-04-13 20:34:37,688 Stage-2 map = 59%,  reduce = 7%
2016-04-13 20:34:40,709 Stage-2 map = 61%,  reduce = 7%
2016-04-13 20:34:43,745 Stage-2 map = 63%,  reduce = 8%
2016-04-13 20:34:46,767 Stage-2 map = 65%,  reduce = 8%
2016-04-13 20:34:49,788 Stage-2 map = 67%,  reduce = 8%
2016-04-13 20:34:55,827 Stage-2 map = 67%,  reduce = 9%
2016-04-13 20:34:58,848 Stage-2 map = 68%,  reduce = 10%
2016-04-13 20:35:00,863 Stage-2 map = 70%,  reduce = 10%
2016-04-13 20:35:01,873 Stage-2 map = 71%,  reduce = 10%
2016-04-13 20:35:03,888 Stage-2 map = 72%,  reduce = 10%
2016-04-13 20:35:04,898 Stage-2 map = 73%,  reduce = 10%
2016-04-13 20:35:07,921 Stage-2 map = 74%,  reduce = 11%
2016-04-13 20:35:10,941 Stage-2 map = 77%,  reduce = 11%
2016-04-13 20:35:12,956 Stage-2 map = 78%,  reduce = 11%
2016-04-13 20:35:13,965 Stage-2 map = 79%,  reduce = 11%
2016-04-13 20:35:15,980 Stage-2 map = 80%,  reduce = 11%
2016-04-13 20:35:17,016 Stage-2 map = 81%,  reduce = 11%
2016-04-13 20:35:19,031 Stage-2 map = 84%,  reduce = 11%
2016-04-13 20:35:22,052 Stage-2 map = 86%,  reduce = 11%
2016-04-13 20:35:25,072 Stage-2 map = 87%,  reduce = 11%
2016-04-13 20:35:28,092 Stage-2 map = 88%,  reduce = 11%
2016-04-13 20:35:31,113 Stage-2 map = 88%,  reduce = 12%
2016-04-13 20:35:34,133 Stage-2 map = 89%,  reduce = 13%
2016-04-13 20:35:37,153 Stage-2 map = 90%,  reduce = 14%
2016-04-13 20:35:40,173 Stage-2 map = 92%,  reduce = 14%
2016-04-13 20:35:43,192 Stage-2 map = 93%,  reduce = 14%
2016-04-13 20:35:46,213 Stage-2 map = 95%,  reduce = 15%
2016-04-13 20:35:49,233 Stage-2 map = 97%,  reduce = 15%
2016-04-13 20:35:52,252 Stage-2 map = 98%,  reduce = 15%
2016-04-13 20:35:55,272 Stage-2 map = 99%,  reduce = 15%
2016-04-13 20:35:58,291 Stage-2 map = 100%,  reduce = 15%
2016-04-13 20:36:01,311 Stage-2 map = 100%,  reduce = 16%
2016-04-13 20:36:10,362 Stage-2 map = 100%,  reduce = 20%
2016-04-13 20:36:13,382 Stage-2 map = 100%,  reduce = 30%
2016-04-13 20:36:16,402 Stage-2 map = 100%,  reduce = 36%
2016-04-13 20:36:19,422 Stage-2 map = 100%,  reduce = 40%
2016-04-13 20:36:22,441 Stage-2 map = 100%,  reduce = 45%
2016-04-13 20:36:25,461 Stage-2 map = 100%,  reduce = 49%
2016-04-13 20:36:28,482 Stage-2 map = 100%,  reduce = 50%
2016-04-13 20:36:34,519 Stage-2 map = 100%,  reduce = 52%
2016-04-13 20:36:37,540 Stage-2 map = 100%,  reduce = 56%
2016-04-13 20:36:40,560 Stage-2 map = 100%,  reduce = 61%
2016-04-13 20:36:43,581 Stage-2 map = 100%,  reduce = 64%
2016-04-13 20:36:46,601 Stage-2 map = 100%,  reduce = 65%
2016-04-13 20:36:49,621 Stage-2 map = 100%,  reduce = 71%
2016-04-13 20:36:52,642 Stage-2 map = 100%,  reduce = 84%
2016-04-13 20:36:55,662 Stage-2 map = 100%,  reduce = 87%
2016-04-13 20:36:58,683 Stage-2 map = 100%,  reduce = 92%
2016-04-13 20:37:01,703 Stage-2 map = 100%,  reduce = 97%
2016-04-13 20:37:04,724 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132031_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132031_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132031_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132031_0003
2016-04-13 20:37:13,316 Stage-3 map = 0%,  reduce = 0%
2016-04-13 20:37:19,344 Stage-3 map = 25%,  reduce = 0%
2016-04-13 20:37:20,353 Stage-3 map = 50%,  reduce = 0%
2016-04-13 20:37:26,394 Stage-3 map = 75%,  reduce = 0%
2016-04-13 20:37:28,407 Stage-3 map = 100%,  reduce = 0%
2016-04-13 20:37:31,424 Stage-3 map = 100%,  reduce = 25%
2016-04-13 20:37:37,456 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132031_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132031_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132031_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132031_0004
2016-04-13 20:37:46,935 Stage-4 map = 0%,  reduce = 0%
2016-04-13 20:37:52,963 Stage-4 map = 100%,  reduce = 0%
2016-04-13 20:38:02,008 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132031_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132031_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132031_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132031_0005
2016-04-13 20:38:10,480 Stage-5 map = 0%,  reduce = 0%
2016-04-13 20:38:13,496 Stage-5 map = 100%,  reduce = 0%
2016-04-13 20:38:22,543 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132031_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 380.856 seconds
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132038_2106577402.txt
OK
Time taken: 3.561 seconds
OK
Time taken: 0.072 seconds
OK
Time taken: 0.058 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 24 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132039_623940702.txt
OK
Time taken: 3.038 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.391 seconds
OK
Time taken: 0.039 seconds
OK
Time taken: 0.049 seconds
OK
Time taken: 0.041 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132038_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132038_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132038_0001
2016-04-13 20:39:13,209 Stage-1 map = 0%,  reduce = 0%
2016-04-13 20:39:22,275 Stage-1 map = 18%,  reduce = 0%
2016-04-13 20:39:25,301 Stage-1 map = 34%,  reduce = 0%
2016-04-13 20:39:28,338 Stage-1 map = 44%,  reduce = 0%
2016-04-13 20:39:31,375 Stage-1 map = 47%,  reduce = 0%
2016-04-13 20:39:34,409 Stage-1 map = 51%,  reduce = 0%
2016-04-13 20:39:37,444 Stage-1 map = 59%,  reduce = 7%
2016-04-13 20:39:40,478 Stage-1 map = 69%,  reduce = 7%
2016-04-13 20:39:43,511 Stage-1 map = 78%,  reduce = 13%
2016-04-13 20:39:46,545 Stage-1 map = 86%,  reduce = 13%
2016-04-13 20:39:49,579 Stage-1 map = 93%,  reduce = 13%
2016-04-13 20:39:52,612 Stage-1 map = 98%,  reduce = 13%
2016-04-13 20:39:55,645 Stage-1 map = 100%,  reduce = 13%
2016-04-13 20:39:57,675 Stage-1 map = 100%,  reduce = 17%
2016-04-13 20:40:01,716 Stage-1 map = 100%,  reduce = 20%
2016-04-13 20:40:06,764 Stage-1 map = 100%,  reduce = 44%
2016-04-13 20:40:07,779 Stage-1 map = 100%,  reduce = 76%
2016-04-13 20:40:09,809 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132038_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132038_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132038_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132038_0002
2016-04-13 20:40:19,602 Stage-2 map = 0%,  reduce = 0%
2016-04-13 20:40:28,655 Stage-2 map = 7%,  reduce = 0%
2016-04-13 20:40:31,675 Stage-2 map = 13%,  reduce = 0%
2016-04-13 20:40:34,698 Stage-2 map = 17%,  reduce = 0%
2016-04-13 20:40:37,725 Stage-2 map = 19%,  reduce = 0%
2016-04-13 20:40:40,753 Stage-2 map = 20%,  reduce = 0%
2016-04-13 20:40:42,776 Stage-2 map = 21%,  reduce = 0%
2016-04-13 20:40:45,802 Stage-2 map = 22%,  reduce = 1%
2016-04-13 20:40:46,831 Stage-2 map = 23%,  reduce = 1%
2016-04-13 20:40:48,853 Stage-2 map = 24%,  reduce = 1%
2016-04-13 20:40:49,865 Stage-2 map = 25%,  reduce = 2%
2016-04-13 20:40:51,886 Stage-2 map = 27%,  reduce = 2%
2016-04-13 20:40:54,914 Stage-2 map = 30%,  reduce = 2%
2016-04-13 20:40:57,943 Stage-2 map = 31%,  reduce = 3%
2016-04-13 20:41:00,969 Stage-2 map = 34%,  reduce = 3%
2016-04-13 20:41:03,996 Stage-2 map = 36%,  reduce = 3%
2016-04-13 20:41:07,024 Stage-2 map = 38%,  reduce = 3%
2016-04-13 20:41:10,051 Stage-2 map = 39%,  reduce = 3%
2016-04-13 20:41:13,079 Stage-2 map = 41%,  reduce = 4%
2016-04-13 20:41:16,106 Stage-2 map = 42%,  reduce = 5%
2016-04-13 20:41:19,131 Stage-2 map = 43%,  reduce = 5%
2016-04-13 20:41:22,156 Stage-2 map = 45%,  reduce = 5%
2016-04-13 20:41:25,183 Stage-2 map = 46%,  reduce = 6%
2016-04-13 20:41:28,207 Stage-2 map = 48%,  reduce = 6%
2016-04-13 20:41:31,231 Stage-2 map = 51%,  reduce = 6%
2016-04-13 20:41:34,255 Stage-2 map = 53%,  reduce = 7%
2016-04-13 20:41:37,281 Stage-2 map = 56%,  reduce = 7%
2016-04-13 20:41:40,303 Stage-2 map = 58%,  reduce = 7%
2016-04-13 20:41:43,325 Stage-2 map = 60%,  reduce = 7%
2016-04-13 20:41:46,348 Stage-2 map = 63%,  reduce = 7%
2016-04-13 20:41:49,370 Stage-2 map = 64%,  reduce = 7%
2016-04-13 20:41:52,392 Stage-2 map = 64%,  reduce = 8%
2016-04-13 20:41:55,414 Stage-2 map = 65%,  reduce = 9%
2016-04-13 20:41:58,435 Stage-2 map = 66%,  reduce = 9%
2016-04-13 20:42:01,457 Stage-2 map = 66%,  reduce = 10%
2016-04-13 20:42:04,479 Stage-2 map = 68%,  reduce = 10%
2016-04-13 20:42:07,514 Stage-2 map = 71%,  reduce = 10%
2016-04-13 20:42:10,535 Stage-2 map = 73%,  reduce = 10%
2016-04-13 20:42:13,556 Stage-2 map = 75%,  reduce = 11%
2016-04-13 20:42:16,576 Stage-2 map = 77%,  reduce = 11%
2016-04-13 20:42:19,596 Stage-2 map = 80%,  reduce = 11%
2016-04-13 20:42:22,617 Stage-2 map = 83%,  reduce = 11%
2016-04-13 20:42:25,638 Stage-2 map = 85%,  reduce = 11%
2016-04-13 20:42:31,676 Stage-2 map = 87%,  reduce = 11%
2016-04-13 20:42:34,697 Stage-2 map = 87%,  reduce = 12%
2016-04-13 20:42:37,718 Stage-2 map = 88%,  reduce = 12%
2016-04-13 20:42:40,739 Stage-2 map = 90%,  reduce = 14%
2016-04-13 20:42:43,759 Stage-2 map = 91%,  reduce = 14%
2016-04-13 20:42:46,780 Stage-2 map = 93%,  reduce = 14%
2016-04-13 20:42:49,800 Stage-2 map = 95%,  reduce = 14%
2016-04-13 20:42:52,821 Stage-2 map = 97%,  reduce = 14%
2016-04-13 20:42:55,841 Stage-2 map = 99%,  reduce = 15%
2016-04-13 20:42:58,860 Stage-2 map = 100%,  reduce = 15%
2016-04-13 20:43:01,880 Stage-2 map = 100%,  reduce = 16%
2016-04-13 20:43:04,900 Stage-2 map = 100%,  reduce = 30%
2016-04-13 20:43:07,920 Stage-2 map = 100%,  reduce = 31%
2016-04-13 20:43:10,939 Stage-2 map = 100%,  reduce = 39%
2016-04-13 20:43:13,959 Stage-2 map = 100%,  reduce = 44%
2016-04-13 20:43:16,979 Stage-2 map = 100%,  reduce = 48%
2016-04-13 20:43:19,999 Stage-2 map = 100%,  reduce = 50%
2016-04-13 20:43:26,036 Stage-2 map = 100%,  reduce = 52%
2016-04-13 20:43:29,057 Stage-2 map = 100%,  reduce = 56%
2016-04-13 20:43:32,078 Stage-2 map = 100%,  reduce = 61%
2016-04-13 20:43:35,098 Stage-2 map = 100%,  reduce = 63%
2016-04-13 20:43:38,118 Stage-2 map = 100%,  reduce = 65%
2016-04-13 20:43:40,133 Stage-2 map = 100%,  reduce = 66%
2016-04-13 20:43:41,142 Stage-2 map = 100%,  reduce = 71%
2016-04-13 20:43:43,157 Stage-2 map = 100%,  reduce = 79%
2016-04-13 20:43:44,165 Stage-2 map = 100%,  reduce = 84%
2016-04-13 20:43:46,180 Stage-2 map = 100%,  reduce = 87%
2016-04-13 20:43:49,200 Stage-2 map = 100%,  reduce = 93%
2016-04-13 20:43:52,220 Stage-2 map = 100%,  reduce = 98%
2016-04-13 20:43:55,239 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132038_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132038_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132038_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132038_0003
2016-04-13 20:44:04,748 Stage-3 map = 0%,  reduce = 0%
2016-04-13 20:44:10,777 Stage-3 map = 50%,  reduce = 0%
2016-04-13 20:44:16,810 Stage-3 map = 75%,  reduce = 0%
2016-04-13 20:44:19,828 Stage-3 map = 100%,  reduce = 0%
2016-04-13 20:44:22,845 Stage-3 map = 100%,  reduce = 25%
2016-04-13 20:44:28,878 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132038_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132038_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132038_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132038_0004
2016-04-13 20:44:37,374 Stage-4 map = 0%,  reduce = 0%
2016-04-13 20:44:43,402 Stage-4 map = 100%,  reduce = 0%
2016-04-13 20:44:52,447 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132038_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132038_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132038_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132038_0005
2016-04-13 20:45:01,897 Stage-5 map = 0%,  reduce = 0%
2016-04-13 20:45:04,912 Stage-5 map = 100%,  reduce = 0%
2016-04-13 20:45:13,959 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132038_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 370.202 seconds
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132045_422296057.txt
OK
Time taken: 3.546 seconds
OK
Time taken: 0.073 seconds
OK
Time taken: 0.058 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 24 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132045_1462495721.txt
OK
Time taken: 3.094 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.009 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.412 seconds
OK
Time taken: 0.039 seconds
OK
Time taken: 0.041 seconds
OK
Time taken: 0.033 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132045_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132045_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132045_0001
2016-04-13 20:46:02,308 Stage-1 map = 0%,  reduce = 0%
2016-04-13 20:46:11,375 Stage-1 map = 5%,  reduce = 0%
2016-04-13 20:46:14,399 Stage-1 map = 8%,  reduce = 0%
2016-04-13 20:46:17,422 Stage-1 map = 25%,  reduce = 0%
2016-04-13 20:46:20,446 Stage-1 map = 45%,  reduce = 0%
2016-04-13 20:46:23,480 Stage-1 map = 62%,  reduce = 0%
2016-04-13 20:46:26,514 Stage-1 map = 67%,  reduce = 0%
2016-04-13 20:46:29,548 Stage-1 map = 70%,  reduce = 0%
2016-04-13 20:46:32,581 Stage-1 map = 79%,  reduce = 7%
2016-04-13 20:46:35,614 Stage-1 map = 88%,  reduce = 7%
2016-04-13 20:46:38,647 Stage-1 map = 94%,  reduce = 13%
2016-04-13 20:46:41,681 Stage-1 map = 99%,  reduce = 13%
2016-04-13 20:46:44,716 Stage-1 map = 100%,  reduce = 13%
2016-04-13 20:46:50,779 Stage-1 map = 100%,  reduce = 40%
2016-04-13 20:46:53,821 Stage-1 map = 100%,  reduce = 95%
2016-04-13 20:46:56,858 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132045_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132045_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132045_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132045_0002
2016-04-13 20:47:05,516 Stage-2 map = 0%,  reduce = 0%
2016-04-13 20:47:14,569 Stage-2 map = 7%,  reduce = 0%
2016-04-13 20:47:17,589 Stage-2 map = 13%,  reduce = 0%
2016-04-13 20:47:20,612 Stage-2 map = 17%,  reduce = 0%
2016-04-13 20:47:23,641 Stage-2 map = 19%,  reduce = 0%
2016-04-13 20:47:26,671 Stage-2 map = 20%,  reduce = 0%
2016-04-13 20:47:29,699 Stage-2 map = 21%,  reduce = 0%
2016-04-13 20:47:32,728 Stage-2 map = 22%,  reduce = 1%
2016-04-13 20:47:35,759 Stage-2 map = 24%,  reduce = 2%
2016-04-13 20:47:38,787 Stage-2 map = 26%,  reduce = 2%
2016-04-13 20:47:41,815 Stage-2 map = 29%,  reduce = 3%
2016-04-13 20:47:44,842 Stage-2 map = 31%,  reduce = 3%
2016-04-13 20:47:47,871 Stage-2 map = 33%,  reduce = 3%
2016-04-13 20:47:50,898 Stage-2 map = 36%,  reduce = 3%
2016-04-13 20:47:53,924 Stage-2 map = 38%,  reduce = 3%
2016-04-13 20:47:56,952 Stage-2 map = 39%,  reduce = 4%
2016-04-13 20:47:59,979 Stage-2 map = 41%,  reduce = 4%
2016-04-13 20:48:03,006 Stage-2 map = 42%,  reduce = 5%
2016-04-13 20:48:06,034 Stage-2 map = 43%,  reduce = 5%
2016-04-13 20:48:09,063 Stage-2 map = 45%,  reduce = 6%
2016-04-13 20:48:12,088 Stage-2 map = 47%,  reduce = 6%
2016-04-13 20:48:15,110 Stage-2 map = 49%,  reduce = 6%
2016-04-13 20:48:18,134 Stage-2 map = 51%,  reduce = 6%
2016-04-13 20:48:21,158 Stage-2 map = 54%,  reduce = 7%
2016-04-13 20:48:24,182 Stage-2 map = 57%,  reduce = 7%
2016-04-13 20:48:27,207 Stage-2 map = 59%,  reduce = 7%
2016-04-13 20:48:30,229 Stage-2 map = 61%,  reduce = 7%
2016-04-13 20:48:33,250 Stage-2 map = 63%,  reduce = 7%
2016-04-13 20:48:36,272 Stage-2 map = 65%,  reduce = 8%
2016-04-13 20:48:39,295 Stage-2 map = 66%,  reduce = 8%
2016-04-13 20:48:42,318 Stage-2 map = 67%,  reduce = 8%
2016-04-13 20:48:45,340 Stage-2 map = 67%,  reduce = 9%
2016-04-13 20:48:48,363 Stage-2 map = 68%,  reduce = 10%
2016-04-13 20:48:51,385 Stage-2 map = 69%,  reduce = 10%
2016-04-13 20:48:54,406 Stage-2 map = 70%,  reduce = 11%
2016-04-13 20:48:57,428 Stage-2 map = 73%,  reduce = 11%
2016-04-13 20:49:00,451 Stage-2 map = 75%,  reduce = 11%
2016-04-13 20:49:02,481 Stage-2 map = 76%,  reduce = 11%
2016-04-13 20:49:03,491 Stage-2 map = 77%,  reduce = 11%
2016-04-13 20:49:05,506 Stage-2 map = 80%,  reduce = 11%
2016-04-13 20:49:08,527 Stage-2 map = 82%,  reduce = 11%
2016-04-13 20:49:11,549 Stage-2 map = 84%,  reduce = 11%
2016-04-13 20:49:14,570 Stage-2 map = 85%,  reduce = 12%
2016-04-13 20:49:17,590 Stage-2 map = 86%,  reduce = 12%
2016-04-13 20:49:20,609 Stage-2 map = 88%,  reduce = 12%
2016-04-13 20:49:24,635 Stage-2 map = 89%,  reduce = 13%
2016-04-13 20:49:26,650 Stage-2 map = 90%,  reduce = 13%
2016-04-13 20:49:29,670 Stage-2 map = 91%,  reduce = 13%
2016-04-13 20:49:32,690 Stage-2 map = 92%,  reduce = 14%
2016-04-13 20:49:33,699 Stage-2 map = 92%,  reduce = 15%
2016-04-13 20:49:35,713 Stage-2 map = 93%,  reduce = 15%
2016-04-13 20:49:38,734 Stage-2 map = 95%,  reduce = 15%
2016-04-13 20:49:41,754 Stage-2 map = 96%,  reduce = 15%
2016-04-13 20:49:44,773 Stage-2 map = 99%,  reduce = 15%
2016-04-13 20:49:47,793 Stage-2 map = 100%,  reduce = 15%
2016-04-13 20:49:56,846 Stage-2 map = 100%,  reduce = 16%
2016-04-13 20:49:59,866 Stage-2 map = 100%,  reduce = 29%
2016-04-13 20:50:02,885 Stage-2 map = 100%,  reduce = 35%
2016-04-13 20:50:05,905 Stage-2 map = 100%,  reduce = 40%
2016-04-13 20:50:08,924 Stage-2 map = 100%,  reduce = 45%
2016-04-13 20:50:11,944 Stage-2 map = 100%,  reduce = 50%
2016-04-13 20:50:21,000 Stage-2 map = 100%,  reduce = 52%
2016-04-13 20:50:24,021 Stage-2 map = 100%,  reduce = 56%
2016-04-13 20:50:27,042 Stage-2 map = 100%,  reduce = 60%
2016-04-13 20:50:30,063 Stage-2 map = 100%,  reduce = 63%
2016-04-13 20:50:33,083 Stage-2 map = 100%,  reduce = 65%
2016-04-13 20:50:36,103 Stage-2 map = 100%,  reduce = 66%
2016-04-13 20:50:39,123 Stage-2 map = 100%,  reduce = 79%
2016-04-13 20:50:42,143 Stage-2 map = 100%,  reduce = 85%
2016-04-13 20:50:45,164 Stage-2 map = 100%,  reduce = 89%
2016-04-13 20:50:48,185 Stage-2 map = 100%,  reduce = 95%
2016-04-13 20:50:51,206 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132045_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132045_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132045_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132045_0003
2016-04-13 20:50:59,805 Stage-3 map = 0%,  reduce = 0%
2016-04-13 20:51:05,834 Stage-3 map = 25%,  reduce = 0%
2016-04-13 20:51:06,842 Stage-3 map = 50%,  reduce = 0%
2016-04-13 20:51:12,874 Stage-3 map = 75%,  reduce = 0%
2016-04-13 20:51:14,887 Stage-3 map = 100%,  reduce = 17%
2016-04-13 20:51:23,935 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132045_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132045_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132045_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132045_0004
2016-04-13 20:51:33,429 Stage-4 map = 0%,  reduce = 0%
2016-04-13 20:51:39,457 Stage-4 map = 100%,  reduce = 0%
2016-04-13 20:51:48,503 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132045_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132045_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132045_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132045_0005
2016-04-13 20:51:56,959 Stage-5 map = 0%,  reduce = 0%
2016-04-13 20:51:59,975 Stage-5 map = 100%,  reduce = 0%
2016-04-13 20:52:09,024 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132045_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 375.678 seconds
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132052_438798844.txt
OK
Time taken: 3.492 seconds
OK
Time taken: 0.074 seconds
OK
Time taken: 0.058 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 24 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132052_979651011.txt
OK
Time taken: 2.945 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.011 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.419 seconds
OK
Time taken: 0.031 seconds
OK
Time taken: 0.033 seconds
OK
Time taken: 0.025 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132052_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132052_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132052_0001
2016-04-13 20:52:59,140 Stage-1 map = 0%,  reduce = 0%
2016-04-13 20:53:08,206 Stage-1 map = 18%,  reduce = 0%
2016-04-13 20:53:11,232 Stage-1 map = 32%,  reduce = 0%
2016-04-13 20:53:14,267 Stage-1 map = 44%,  reduce = 0%
2016-04-13 20:53:17,304 Stage-1 map = 47%,  reduce = 0%
2016-04-13 20:53:20,338 Stage-1 map = 51%,  reduce = 0%
2016-04-13 20:53:23,373 Stage-1 map = 60%,  reduce = 7%
2016-04-13 20:53:26,405 Stage-1 map = 69%,  reduce = 13%
2016-04-13 20:53:29,439 Stage-1 map = 77%,  reduce = 13%
2016-04-13 20:53:32,472 Stage-1 map = 86%,  reduce = 13%
2016-04-13 20:53:35,504 Stage-1 map = 92%,  reduce = 13%
2016-04-13 20:53:38,539 Stage-1 map = 97%,  reduce = 13%
2016-04-13 20:53:41,572 Stage-1 map = 100%,  reduce = 17%
2016-04-13 20:53:46,629 Stage-1 map = 100%,  reduce = 20%
2016-04-13 20:53:49,662 Stage-1 map = 100%,  reduce = 44%
2016-04-13 20:53:52,693 Stage-1 map = 100%,  reduce = 86%
2016-04-13 20:53:55,730 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132052_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132052_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132052_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132052_0002
2016-04-13 20:54:05,432 Stage-2 map = 0%,  reduce = 0%
2016-04-13 20:54:14,486 Stage-2 map = 7%,  reduce = 0%
2016-04-13 20:54:17,506 Stage-2 map = 13%,  reduce = 0%
2016-04-13 20:54:20,528 Stage-2 map = 17%,  reduce = 0%
2016-04-13 20:54:23,555 Stage-2 map = 19%,  reduce = 0%
2016-04-13 20:54:26,583 Stage-2 map = 20%,  reduce = 0%
2016-04-13 20:54:29,612 Stage-2 map = 22%,  reduce = 0%
2016-04-13 20:54:32,641 Stage-2 map = 23%,  reduce = 1%
2016-04-13 20:54:35,672 Stage-2 map = 25%,  reduce = 2%
2016-04-13 20:54:37,693 Stage-2 map = 26%,  reduce = 2%
2016-04-13 20:54:38,706 Stage-2 map = 27%,  reduce = 2%
2016-04-13 20:54:40,727 Stage-2 map = 29%,  reduce = 3%
2016-04-13 20:54:43,757 Stage-2 map = 31%,  reduce = 3%
2016-04-13 20:54:46,786 Stage-2 map = 34%,  reduce = 3%
2016-04-13 20:54:49,813 Stage-2 map = 36%,  reduce = 3%
2016-04-13 20:54:52,839 Stage-2 map = 38%,  reduce = 4%
2016-04-13 20:54:55,867 Stage-2 map = 39%,  reduce = 4%
2016-04-13 20:54:58,895 Stage-2 map = 41%,  reduce = 4%
2016-04-13 20:55:01,923 Stage-2 map = 42%,  reduce = 5%
2016-04-13 20:55:04,948 Stage-2 map = 43%,  reduce = 5%
2016-04-13 20:55:07,972 Stage-2 map = 45%,  reduce = 6%
2016-04-13 20:55:10,999 Stage-2 map = 47%,  reduce = 6%
2016-04-13 20:55:14,022 Stage-2 map = 49%,  reduce = 6%
2016-04-13 20:55:17,047 Stage-2 map = 51%,  reduce = 6%
2016-04-13 20:55:20,072 Stage-2 map = 54%,  reduce = 7%
2016-04-13 20:55:23,096 Stage-2 map = 56%,  reduce = 7%
2016-04-13 20:55:26,120 Stage-2 map = 58%,  reduce = 7%
2016-04-13 20:55:29,142 Stage-2 map = 61%,  reduce = 7%
2016-04-13 20:55:32,164 Stage-2 map = 62%,  reduce = 7%
2016-04-13 20:55:35,187 Stage-2 map = 63%,  reduce = 7%
2016-04-13 20:55:38,208 Stage-2 map = 64%,  reduce = 8%
2016-04-13 20:55:41,230 Stage-2 map = 66%,  reduce = 8%
2016-04-13 20:55:44,252 Stage-2 map = 66%,  reduce = 9%
2016-04-13 20:55:47,274 Stage-2 map = 67%,  reduce = 10%
2016-04-13 20:55:50,295 Stage-2 map = 69%,  reduce = 10%
2016-04-13 20:55:53,318 Stage-2 map = 71%,  reduce = 10%
2016-04-13 20:55:56,342 Stage-2 map = 74%,  reduce = 10%
2016-04-13 20:55:59,378 Stage-2 map = 76%,  reduce = 10%
2016-04-13 20:56:02,400 Stage-2 map = 78%,  reduce = 11%
2016-04-13 20:56:05,421 Stage-2 map = 80%,  reduce = 11%
2016-04-13 20:56:08,444 Stage-2 map = 82%,  reduce = 11%
2016-04-13 20:56:11,467 Stage-2 map = 84%,  reduce = 11%
2016-04-13 20:56:14,486 Stage-2 map = 84%,  reduce = 12%
2016-04-13 20:56:17,506 Stage-2 map = 86%,  reduce = 12%
2016-04-13 20:56:20,526 Stage-2 map = 87%,  reduce = 12%
2016-04-13 20:56:23,546 Stage-2 map = 88%,  reduce = 13%
2016-04-13 20:56:26,567 Stage-2 map = 90%,  reduce = 13%
2016-04-13 20:56:29,588 Stage-2 map = 92%,  reduce = 14%
2016-04-13 20:56:32,611 Stage-2 map = 93%,  reduce = 14%
2016-04-13 20:56:35,631 Stage-2 map = 95%,  reduce = 14%
2016-04-13 20:56:38,651 Stage-2 map = 97%,  reduce = 14%
2016-04-13 20:56:41,672 Stage-2 map = 98%,  reduce = 14%
2016-04-13 20:56:44,692 Stage-2 map = 99%,  reduce = 14%
2016-04-13 20:56:47,712 Stage-2 map = 100%,  reduce = 15%
2016-04-13 20:56:56,764 Stage-2 map = 100%,  reduce = 16%
2016-04-13 20:56:59,786 Stage-2 map = 100%,  reduce = 20%
2016-04-13 20:57:02,805 Stage-2 map = 100%,  reduce = 31%
2016-04-13 20:57:05,825 Stage-2 map = 100%,  reduce = 39%
2016-04-13 20:57:08,845 Stage-2 map = 100%,  reduce = 44%
2016-04-13 20:57:11,866 Stage-2 map = 100%,  reduce = 48%
2016-04-13 20:57:14,888 Stage-2 map = 100%,  reduce = 50%
2016-04-13 20:57:20,926 Stage-2 map = 100%,  reduce = 52%
2016-04-13 20:57:23,947 Stage-2 map = 100%,  reduce = 56%
2016-04-13 20:57:26,968 Stage-2 map = 100%,  reduce = 61%
2016-04-13 20:57:29,988 Stage-2 map = 100%,  reduce = 63%
2016-04-13 20:57:33,007 Stage-2 map = 100%,  reduce = 65%
2016-04-13 20:57:35,022 Stage-2 map = 100%,  reduce = 66%
2016-04-13 20:57:38,042 Stage-2 map = 100%,  reduce = 71%
2016-04-13 20:57:39,051 Stage-2 map = 100%,  reduce = 79%
2016-04-13 20:57:41,066 Stage-2 map = 100%,  reduce = 85%
2016-04-13 20:57:42,076 Stage-2 map = 100%,  reduce = 86%
2016-04-13 20:57:44,091 Stage-2 map = 100%,  reduce = 88%
2016-04-13 20:57:45,100 Stage-2 map = 100%,  reduce = 91%
2016-04-13 20:57:47,115 Stage-2 map = 100%,  reduce = 94%
2016-04-13 20:57:48,125 Stage-2 map = 100%,  reduce = 97%
2016-04-13 20:57:50,139 Stage-2 map = 100%,  reduce = 99%
2016-04-13 20:57:51,149 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132052_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132052_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132052_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132052_0003
2016-04-13 20:57:59,678 Stage-3 map = 0%,  reduce = 0%
2016-04-13 20:58:05,707 Stage-3 map = 50%,  reduce = 0%
2016-04-13 20:58:11,740 Stage-3 map = 75%,  reduce = 0%
2016-04-13 20:58:14,759 Stage-3 map = 100%,  reduce = 17%
2016-04-13 20:58:23,807 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132052_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132052_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132052_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132052_0004
2016-04-13 20:58:32,307 Stage-4 map = 0%,  reduce = 0%
2016-04-13 20:58:38,335 Stage-4 map = 100%,  reduce = 0%
2016-04-13 20:58:47,380 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132052_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132052_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132052_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132052_0005
2016-04-13 20:58:56,851 Stage-5 map = 0%,  reduce = 0%
2016-04-13 20:58:59,866 Stage-5 map = 100%,  reduce = 0%
2016-04-13 20:59:08,914 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132052_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 379.385 seconds
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132059_692503937.txt
OK
Time taken: 3.316 seconds
OK
Time taken: 0.065 seconds
OK
Time taken: 0.059 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 24 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132059_1029374897.txt
OK
Time taken: 2.947 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.011 seconds
OK
Time taken: 0.01 seconds
OK
Time taken: 0.63 seconds
OK
Time taken: 0.088 seconds
OK
Time taken: 0.066 seconds
OK
Time taken: 0.041 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132059_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132059_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132059_0001
2016-04-13 20:59:59,069 Stage-1 map = 0%,  reduce = 0%
2016-04-13 21:00:08,135 Stage-1 map = 18%,  reduce = 0%
2016-04-13 21:00:11,161 Stage-1 map = 35%,  reduce = 0%
2016-04-13 21:00:14,197 Stage-1 map = 44%,  reduce = 0%
2016-04-13 21:00:17,232 Stage-1 map = 47%,  reduce = 0%
2016-04-13 21:00:20,266 Stage-1 map = 50%,  reduce = 0%
2016-04-13 21:00:23,300 Stage-1 map = 60%,  reduce = 13%
2016-04-13 21:00:26,333 Stage-1 map = 69%,  reduce = 13%
2016-04-13 21:00:29,367 Stage-1 map = 79%,  reduce = 13%
2016-04-13 21:00:32,401 Stage-1 map = 87%,  reduce = 13%
2016-04-13 21:00:35,434 Stage-1 map = 92%,  reduce = 13%
2016-04-13 21:00:38,469 Stage-1 map = 97%,  reduce = 20%
2016-04-13 21:00:41,502 Stage-1 map = 100%,  reduce = 20%
2016-04-13 21:00:53,619 Stage-1 map = 100%,  reduce = 82%
2016-04-13 21:00:56,665 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132059_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132059_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132059_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132059_0002
2016-04-13 21:01:05,483 Stage-2 map = 0%,  reduce = 0%
2016-04-13 21:01:14,537 Stage-2 map = 7%,  reduce = 0%
2016-04-13 21:01:17,557 Stage-2 map = 13%,  reduce = 0%
2016-04-13 21:01:20,580 Stage-2 map = 17%,  reduce = 0%
2016-04-13 21:01:23,608 Stage-2 map = 19%,  reduce = 0%
2016-04-13 21:01:26,636 Stage-2 map = 21%,  reduce = 0%
2016-04-13 21:01:29,664 Stage-2 map = 22%,  reduce = 1%
2016-04-13 21:01:32,694 Stage-2 map = 23%,  reduce = 2%
2016-04-13 21:01:34,717 Stage-2 map = 24%,  reduce = 2%
2016-04-13 21:01:35,729 Stage-2 map = 25%,  reduce = 2%
2016-04-13 21:01:37,750 Stage-2 map = 27%,  reduce = 3%
2016-04-13 21:01:40,778 Stage-2 map = 29%,  reduce = 3%
2016-04-13 21:01:43,807 Stage-2 map = 32%,  reduce = 3%
2016-04-13 21:01:46,837 Stage-2 map = 34%,  reduce = 3%
2016-04-13 21:01:49,865 Stage-2 map = 36%,  reduce = 3%
2016-04-13 21:01:52,893 Stage-2 map = 38%,  reduce = 4%
2016-04-13 21:01:55,921 Stage-2 map = 39%,  reduce = 4%
2016-04-13 21:01:58,949 Stage-2 map = 40%,  reduce = 4%
2016-04-13 21:01:59,966 Stage-2 map = 41%,  reduce = 4%
2016-04-13 21:02:02,994 Stage-2 map = 43%,  reduce = 4%
2016-04-13 21:02:05,012 Stage-2 map = 44%,  reduce = 4%
2016-04-13 21:02:08,038 Stage-2 map = 45%,  reduce = 4%
2016-04-13 21:02:09,049 Stage-2 map = 45%,  reduce = 5%
2016-04-13 21:02:11,066 Stage-2 map = 46%,  reduce = 5%
2016-04-13 21:02:12,077 Stage-2 map = 47%,  reduce = 6%
2016-04-13 21:02:14,095 Stage-2 map = 48%,  reduce = 6%
2016-04-13 21:02:15,108 Stage-2 map = 49%,  reduce = 6%
2016-04-13 21:02:17,125 Stage-2 map = 51%,  reduce = 7%
2016-04-13 21:02:20,149 Stage-2 map = 54%,  reduce = 7%
2016-04-13 21:02:23,173 Stage-2 map = 56%,  reduce = 7%
2016-04-13 21:02:26,196 Stage-2 map = 58%,  reduce = 7%
2016-04-13 21:02:29,218 Stage-2 map = 60%,  reduce = 7%
2016-04-13 21:02:32,241 Stage-2 map = 63%,  reduce = 7%
2016-04-13 21:02:35,264 Stage-2 map = 65%,  reduce = 8%
2016-04-13 21:02:38,287 Stage-2 map = 66%,  reduce = 8%
2016-04-13 21:02:41,310 Stage-2 map = 67%,  reduce = 8%
2016-04-13 21:02:44,333 Stage-2 map = 68%,  reduce = 8%
2016-04-13 21:02:47,356 Stage-2 map = 69%,  reduce = 9%
2016-04-13 21:02:50,379 Stage-2 map = 70%,  reduce = 10%
2016-04-13 21:02:53,401 Stage-2 map = 71%,  reduce = 11%
2016-04-13 21:02:56,437 Stage-2 map = 74%,  reduce = 11%
2016-04-13 21:02:59,458 Stage-2 map = 76%,  reduce = 11%
2016-04-13 21:03:02,479 Stage-2 map = 78%,  reduce = 11%
2016-04-13 21:03:05,500 Stage-2 map = 81%,  reduce = 11%
2016-04-13 21:03:08,522 Stage-2 map = 83%,  reduce = 11%
2016-04-13 21:03:11,543 Stage-2 map = 86%,  reduce = 11%
2016-04-13 21:03:14,564 Stage-2 map = 87%,  reduce = 11%
2016-04-13 21:03:17,585 Stage-2 map = 88%,  reduce = 12%
2016-04-13 21:03:20,607 Stage-2 map = 89%,  reduce = 12%
2016-04-13 21:03:23,628 Stage-2 map = 90%,  reduce = 12%
2016-04-13 21:03:26,649 Stage-2 map = 91%,  reduce = 13%
2016-04-13 21:03:29,670 Stage-2 map = 92%,  reduce = 14%
2016-04-13 21:03:32,690 Stage-2 map = 93%,  reduce = 14%
2016-04-13 21:03:35,710 Stage-2 map = 94%,  reduce = 15%
2016-04-13 21:03:38,730 Stage-2 map = 95%,  reduce = 15%
2016-04-13 21:03:41,750 Stage-2 map = 97%,  reduce = 15%
2016-04-13 21:03:44,770 Stage-2 map = 98%,  reduce = 15%
2016-04-13 21:03:47,791 Stage-2 map = 99%,  reduce = 15%
2016-04-13 21:03:50,812 Stage-2 map = 100%,  reduce = 15%
2016-04-13 21:03:56,848 Stage-2 map = 100%,  reduce = 16%
2016-04-13 21:03:59,868 Stage-2 map = 100%,  reduce = 21%
2016-04-13 21:04:02,888 Stage-2 map = 100%,  reduce = 32%
2016-04-13 21:04:05,908 Stage-2 map = 100%,  reduce = 41%
2016-04-13 21:04:08,929 Stage-2 map = 100%,  reduce = 46%
2016-04-13 21:04:11,952 Stage-2 map = 100%,  reduce = 50%
2016-04-13 21:04:21,008 Stage-2 map = 100%,  reduce = 53%
2016-04-13 21:04:24,029 Stage-2 map = 100%,  reduce = 59%
2016-04-13 21:04:27,050 Stage-2 map = 100%,  reduce = 62%
2016-04-13 21:04:30,071 Stage-2 map = 100%,  reduce = 64%
2016-04-13 21:04:33,092 Stage-2 map = 100%,  reduce = 66%
2016-04-13 21:04:36,112 Stage-2 map = 100%,  reduce = 75%
2016-04-13 21:04:39,132 Stage-2 map = 100%,  reduce = 84%
2016-04-13 21:04:42,151 Stage-2 map = 100%,  reduce = 88%
2016-04-13 21:04:45,171 Stage-2 map = 100%,  reduce = 93%
2016-04-13 21:04:48,193 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132059_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132059_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132059_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132059_0003
2016-04-13 21:04:56,810 Stage-3 map = 0%,  reduce = 0%
2016-04-13 21:05:02,840 Stage-3 map = 50%,  reduce = 0%
2016-04-13 21:05:08,874 Stage-3 map = 75%,  reduce = 0%
2016-04-13 21:05:11,891 Stage-3 map = 100%,  reduce = 0%
2016-04-13 21:05:14,909 Stage-3 map = 100%,  reduce = 17%
2016-04-13 21:05:20,941 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132059_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132059_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132059_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132059_0004
2016-04-13 21:05:30,397 Stage-4 map = 0%,  reduce = 0%
2016-04-13 21:05:36,425 Stage-4 map = 100%,  reduce = 0%
2016-04-13 21:05:45,472 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132059_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132059_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132059_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132059_0005
2016-04-13 21:05:53,971 Stage-5 map = 0%,  reduce = 0%
2016-04-13 21:05:56,987 Stage-5 map = 100%,  reduce = 0%
2016-04-13 21:06:06,036 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132059_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 376.553 seconds
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132106_299154690.txt
OK
Time taken: 3.546 seconds
OK
Time taken: 0.073 seconds
OK
Time taken: 0.058 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 24 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132106_29178354.txt
OK
Time taken: 2.861 seconds
OK
Time taken: 0.011 seconds
OK
Time taken: 0.01 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.425 seconds
OK
Time taken: 0.047 seconds
OK
Time taken: 0.033 seconds
OK
Time taken: 0.025 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132106_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132106_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132106_0001
2016-04-13 21:06:55,671 Stage-1 map = 0%,  reduce = 0%
2016-04-13 21:07:04,738 Stage-1 map = 5%,  reduce = 0%
2016-04-13 21:07:07,762 Stage-1 map = 8%,  reduce = 0%
2016-04-13 21:07:10,785 Stage-1 map = 26%,  reduce = 0%
2016-04-13 21:07:13,807 Stage-1 map = 45%,  reduce = 0%
2016-04-13 21:07:16,841 Stage-1 map = 62%,  reduce = 0%
2016-04-13 21:07:19,875 Stage-1 map = 67%,  reduce = 0%
2016-04-13 21:07:22,908 Stage-1 map = 70%,  reduce = 0%
2016-04-13 21:07:25,942 Stage-1 map = 79%,  reduce = 7%
2016-04-13 21:07:28,976 Stage-1 map = 88%,  reduce = 7%
2016-04-13 21:07:32,009 Stage-1 map = 94%,  reduce = 13%
2016-04-13 21:07:35,043 Stage-1 map = 99%,  reduce = 13%
2016-04-13 21:07:38,079 Stage-1 map = 100%,  reduce = 13%
2016-04-13 21:07:44,141 Stage-1 map = 100%,  reduce = 40%
2016-04-13 21:07:47,182 Stage-1 map = 100%,  reduce = 94%
2016-04-13 21:07:50,222 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132106_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132106_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132106_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132106_0002
2016-04-13 21:07:59,281 Stage-2 map = 0%,  reduce = 0%
2016-04-13 21:08:08,335 Stage-2 map = 7%,  reduce = 0%
2016-04-13 21:08:11,356 Stage-2 map = 13%,  reduce = 0%
2016-04-13 21:08:14,379 Stage-2 map = 17%,  reduce = 0%
2016-04-13 21:08:17,407 Stage-2 map = 19%,  reduce = 0%
2016-04-13 21:08:20,436 Stage-2 map = 20%,  reduce = 0%
2016-04-13 21:08:23,466 Stage-2 map = 21%,  reduce = 0%
2016-04-13 21:08:25,486 Stage-2 map = 22%,  reduce = 0%
2016-04-13 21:08:26,500 Stage-2 map = 22%,  reduce = 1%
2016-04-13 21:08:28,524 Stage-2 map = 24%,  reduce = 2%
2016-04-13 21:08:31,561 Stage-2 map = 26%,  reduce = 2%
2016-04-13 21:08:34,589 Stage-2 map = 29%,  reduce = 2%
2016-04-13 21:08:37,617 Stage-2 map = 31%,  reduce = 3%
2016-04-13 21:08:40,646 Stage-2 map = 33%,  reduce = 3%
2016-04-13 21:08:43,674 Stage-2 map = 35%,  reduce = 3%
2016-04-13 21:08:46,701 Stage-2 map = 38%,  reduce = 3%
2016-04-13 21:08:49,730 Stage-2 map = 39%,  reduce = 4%
2016-04-13 21:08:52,757 Stage-2 map = 41%,  reduce = 4%
2016-04-13 21:08:55,784 Stage-2 map = 42%,  reduce = 5%
2016-04-13 21:08:58,814 Stage-2 map = 44%,  reduce = 5%
2016-04-13 21:09:01,842 Stage-2 map = 45%,  reduce = 6%
2016-04-13 21:09:04,866 Stage-2 map = 47%,  reduce = 6%
2016-04-13 21:09:07,890 Stage-2 map = 49%,  reduce = 6%
2016-04-13 21:09:10,914 Stage-2 map = 51%,  reduce = 6%
2016-04-13 21:09:13,938 Stage-2 map = 54%,  reduce = 7%
2016-04-13 21:09:16,963 Stage-2 map = 56%,  reduce = 7%
2016-04-13 21:09:19,989 Stage-2 map = 59%,  reduce = 7%
2016-04-13 21:09:23,014 Stage-2 map = 61%,  reduce = 7%
2016-04-13 21:09:26,036 Stage-2 map = 62%,  reduce = 7%
2016-04-13 21:09:29,057 Stage-2 map = 64%,  reduce = 8%
2016-04-13 21:09:32,079 Stage-2 map = 65%,  reduce = 8%
2016-04-13 21:09:35,101 Stage-2 map = 66%,  reduce = 8%
2016-04-13 21:09:38,123 Stage-2 map = 67%,  reduce = 9%
2016-04-13 21:09:41,145 Stage-2 map = 68%,  reduce = 10%
2016-04-13 21:09:44,167 Stage-2 map = 70%,  reduce = 10%
2016-04-13 21:09:47,189 Stage-2 map = 72%,  reduce = 10%
2016-04-13 21:09:50,210 Stage-2 map = 75%,  reduce = 10%
2016-04-13 21:09:53,250 Stage-2 map = 77%,  reduce = 11%
2016-04-13 21:09:56,271 Stage-2 map = 79%,  reduce = 11%
2016-04-13 21:09:59,292 Stage-2 map = 80%,  reduce = 11%
2016-04-13 21:10:02,312 Stage-2 map = 83%,  reduce = 11%
2016-04-13 21:10:05,334 Stage-2 map = 84%,  reduce = 11%
2016-04-13 21:10:08,355 Stage-2 map = 85%,  reduce = 12%
2016-04-13 21:10:14,392 Stage-2 map = 87%,  reduce = 13%
2016-04-13 21:10:17,413 Stage-2 map = 88%,  reduce = 14%
2016-04-13 21:10:20,433 Stage-2 map = 91%,  reduce = 14%
2016-04-13 21:10:23,453 Stage-2 map = 93%,  reduce = 14%
2016-04-13 21:10:26,473 Stage-2 map = 95%,  reduce = 14%
2016-04-13 21:10:29,494 Stage-2 map = 96%,  reduce = 14%
2016-04-13 21:10:32,515 Stage-2 map = 99%,  reduce = 14%
2016-04-13 21:10:35,536 Stage-2 map = 100%,  reduce = 14%
2016-04-13 21:10:41,573 Stage-2 map = 100%,  reduce = 15%
2016-04-13 21:10:47,612 Stage-2 map = 100%,  reduce = 16%
2016-04-13 21:10:50,632 Stage-2 map = 100%,  reduce = 30%
2016-04-13 21:10:53,652 Stage-2 map = 100%,  reduce = 38%
2016-04-13 21:10:56,672 Stage-2 map = 100%,  reduce = 43%
2016-04-13 21:10:59,693 Stage-2 map = 100%,  reduce = 49%
2016-04-13 21:11:02,715 Stage-2 map = 100%,  reduce = 50%
2016-04-13 21:11:08,752 Stage-2 map = 100%,  reduce = 54%
2016-04-13 21:11:11,774 Stage-2 map = 100%,  reduce = 59%
2016-04-13 21:11:13,789 Stage-2 map = 100%,  reduce = 61%
2016-04-13 21:11:14,798 Stage-2 map = 100%,  reduce = 62%
2016-04-13 21:11:16,813 Stage-2 map = 100%,  reduce = 63%
2016-04-13 21:11:17,822 Stage-2 map = 100%,  reduce = 64%
2016-04-13 21:11:19,837 Stage-2 map = 100%,  reduce = 65%
2016-04-13 21:11:20,846 Stage-2 map = 100%,  reduce = 66%
2016-04-13 21:11:22,861 Stage-2 map = 100%,  reduce = 70%
2016-04-13 21:11:23,870 Stage-2 map = 100%,  reduce = 75%
2016-04-13 21:11:25,885 Stage-2 map = 100%,  reduce = 80%
2016-04-13 21:11:26,894 Stage-2 map = 100%,  reduce = 84%
2016-04-13 21:11:28,909 Stage-2 map = 100%,  reduce = 86%
2016-04-13 21:11:29,918 Stage-2 map = 100%,  reduce = 88%
2016-04-13 21:11:31,932 Stage-2 map = 100%,  reduce = 91%
2016-04-13 21:11:32,941 Stage-2 map = 100%,  reduce = 93%
2016-04-13 21:11:34,958 Stage-2 map = 100%,  reduce = 96%
2016-04-13 21:11:35,967 Stage-2 map = 100%,  reduce = 99%
2016-04-13 21:11:37,980 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132106_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132106_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132106_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132106_0003
2016-04-13 21:11:47,484 Stage-3 map = 0%,  reduce = 0%
2016-04-13 21:11:53,514 Stage-3 map = 50%,  reduce = 0%
2016-04-13 21:11:59,547 Stage-3 map = 75%,  reduce = 0%
2016-04-13 21:12:02,566 Stage-3 map = 100%,  reduce = 0%
2016-04-13 21:12:05,583 Stage-3 map = 100%,  reduce = 17%
2016-04-13 21:12:11,617 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132106_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132106_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132106_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132106_0004
2016-04-13 21:12:20,151 Stage-4 map = 0%,  reduce = 0%
2016-04-13 21:12:26,179 Stage-4 map = 100%,  reduce = 0%
2016-04-13 21:12:35,231 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132106_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132106_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132106_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132106_0005
2016-04-13 21:12:44,683 Stage-5 map = 0%,  reduce = 0%
2016-04-13 21:12:47,698 Stage-5 map = 100%,  reduce = 0%
2016-04-13 21:12:56,747 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132106_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 370.504 seconds
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132113_1252517636.txt
OK
Time taken: 3.371 seconds
OK
Time taken: 0.082 seconds
OK
Time taken: 0.058 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q3_shipping_priority. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 24 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604132113_506224436.txt
OK
Time taken: 2.902 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.439 seconds
OK
Time taken: 0.037 seconds
OK
Time taken: 0.042 seconds
OK
Time taken: 0.033 seconds
Total MapReduce jobs = 5
Launching Job 1 out of 5
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132113_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132113_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132113_0001
2016-04-13 21:13:46,481 Stage-1 map = 0%,  reduce = 0%
2016-04-13 21:13:55,547 Stage-1 map = 5%,  reduce = 0%
2016-04-13 21:13:58,577 Stage-1 map = 8%,  reduce = 0%
2016-04-13 21:14:01,601 Stage-1 map = 25%,  reduce = 0%
2016-04-13 21:14:04,623 Stage-1 map = 45%,  reduce = 0%
2016-04-13 21:14:07,658 Stage-1 map = 61%,  reduce = 0%
2016-04-13 21:14:10,691 Stage-1 map = 66%,  reduce = 0%
2016-04-13 21:14:13,724 Stage-1 map = 70%,  reduce = 0%
2016-04-13 21:14:16,757 Stage-1 map = 78%,  reduce = 7%
2016-04-13 21:14:19,790 Stage-1 map = 87%,  reduce = 7%
2016-04-13 21:14:22,822 Stage-1 map = 94%,  reduce = 13%
2016-04-13 21:14:25,857 Stage-1 map = 98%,  reduce = 13%
2016-04-13 21:14:28,891 Stage-1 map = 100%,  reduce = 13%
2016-04-13 21:14:34,953 Stage-1 map = 100%,  reduce = 40%
2016-04-13 21:14:36,977 Stage-1 map = 100%,  reduce = 81%
2016-04-13 21:14:40,016 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604132113_0001
Launching Job 2 out of 5
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132113_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132113_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132113_0002
2016-04-13 21:14:49,758 Stage-2 map = 0%,  reduce = 0%
2016-04-13 21:14:58,810 Stage-2 map = 7%,  reduce = 0%
2016-04-13 21:15:01,829 Stage-2 map = 13%,  reduce = 0%
2016-04-13 21:15:04,852 Stage-2 map = 17%,  reduce = 0%
2016-04-13 21:15:07,881 Stage-2 map = 19%,  reduce = 0%
2016-04-13 21:15:10,909 Stage-2 map = 20%,  reduce = 0%
2016-04-13 21:15:13,938 Stage-2 map = 21%,  reduce = 0%
2016-04-13 21:15:16,966 Stage-2 map = 22%,  reduce = 1%
2016-04-13 21:15:18,987 Stage-2 map = 24%,  reduce = 1%
2016-04-13 21:15:20,001 Stage-2 map = 25%,  reduce = 2%
2016-04-13 21:15:22,023 Stage-2 map = 26%,  reduce = 2%
2016-04-13 21:15:25,052 Stage-2 map = 29%,  reduce = 2%
2016-04-13 21:15:28,081 Stage-2 map = 31%,  reduce = 3%
2016-04-13 21:15:31,110 Stage-2 map = 33%,  reduce = 3%
2016-04-13 21:15:34,139 Stage-2 map = 36%,  reduce = 3%
2016-04-13 21:15:37,167 Stage-2 map = 38%,  reduce = 3%
2016-04-13 21:15:40,195 Stage-2 map = 39%,  reduce = 4%
2016-04-13 21:15:43,224 Stage-2 map = 41%,  reduce = 4%
2016-04-13 21:15:46,251 Stage-2 map = 42%,  reduce = 5%
2016-04-13 21:15:49,278 Stage-2 map = 43%,  reduce = 5%
2016-04-13 21:15:52,308 Stage-2 map = 45%,  reduce = 6%
2016-04-13 21:15:55,333 Stage-2 map = 47%,  reduce = 6%
2016-04-13 21:15:58,358 Stage-2 map = 49%,  reduce = 6%
2016-04-13 21:16:01,382 Stage-2 map = 51%,  reduce = 6%
2016-04-13 21:16:04,406 Stage-2 map = 54%,  reduce = 7%
2016-04-13 21:16:07,430 Stage-2 map = 56%,  reduce = 7%
2016-04-13 21:16:10,456 Stage-2 map = 58%,  reduce = 7%
2016-04-13 21:16:13,479 Stage-2 map = 61%,  reduce = 7%
2016-04-13 21:16:16,502 Stage-2 map = 62%,  reduce = 7%
2016-04-13 21:16:19,526 Stage-2 map = 64%,  reduce = 8%
2016-04-13 21:16:22,549 Stage-2 map = 66%,  reduce = 9%
2016-04-13 21:16:28,592 Stage-2 map = 67%,  reduce = 10%
2016-04-13 21:16:31,613 Stage-2 map = 68%,  reduce = 10%
2016-04-13 21:16:34,635 Stage-2 map = 70%,  reduce = 10%
2016-04-13 21:16:37,656 Stage-2 map = 72%,  reduce = 10%
2016-04-13 21:16:40,677 Stage-2 map = 75%,  reduce = 10%
2016-04-13 21:16:43,700 Stage-2 map = 77%,  reduce = 11%
2016-04-13 21:16:46,721 Stage-2 map = 79%,  reduce = 11%
2016-04-13 21:16:49,758 Stage-2 map = 81%,  reduce = 11%
2016-04-13 21:16:52,781 Stage-2 map = 83%,  reduce = 11%
2016-04-13 21:16:55,803 Stage-2 map = 84%,  reduce = 11%
2016-04-13 21:16:58,828 Stage-2 map = 85%,  reduce = 12%
2016-04-13 21:17:01,848 Stage-2 map = 87%,  reduce = 12%
2016-04-13 21:17:04,868 Stage-2 map = 89%,  reduce = 12%
2016-04-13 21:17:07,889 Stage-2 map = 91%,  reduce = 13%
2016-04-13 21:17:10,910 Stage-2 map = 92%,  reduce = 14%
2016-04-13 21:17:13,930 Stage-2 map = 94%,  reduce = 14%
2016-04-13 21:17:16,949 Stage-2 map = 96%,  reduce = 14%
2016-04-13 21:17:19,969 Stage-2 map = 98%,  reduce = 14%
2016-04-13 21:17:22,990 Stage-2 map = 99%,  reduce = 14%
2016-04-13 21:17:26,010 Stage-2 map = 100%,  reduce = 14%
2016-04-13 21:17:29,030 Stage-2 map = 100%,  reduce = 15%
2016-04-13 21:17:38,083 Stage-2 map = 100%,  reduce = 24%
2016-04-13 21:17:41,102 Stage-2 map = 100%,  reduce = 36%
2016-04-13 21:17:44,122 Stage-2 map = 100%,  reduce = 40%
2016-04-13 21:17:47,142 Stage-2 map = 100%,  reduce = 45%
2016-04-13 21:17:50,162 Stage-2 map = 100%,  reduce = 50%
2016-04-13 21:17:59,217 Stage-2 map = 100%,  reduce = 54%
2016-04-13 21:18:02,237 Stage-2 map = 100%,  reduce = 59%
2016-04-13 21:18:05,258 Stage-2 map = 100%,  reduce = 62%
2016-04-13 21:18:08,278 Stage-2 map = 100%,  reduce = 64%
2016-04-13 21:18:11,298 Stage-2 map = 100%,  reduce = 66%
2016-04-13 21:18:14,319 Stage-2 map = 100%,  reduce = 75%
2016-04-13 21:18:17,340 Stage-2 map = 100%,  reduce = 84%
2016-04-13 21:18:20,360 Stage-2 map = 100%,  reduce = 88%
2016-04-13 21:18:23,381 Stage-2 map = 100%,  reduce = 93%
2016-04-13 21:18:26,403 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604132113_0002
Launching Job 3 out of 5
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132113_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132113_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132113_0003
2016-04-13 21:18:34,962 Stage-3 map = 0%,  reduce = 0%
2016-04-13 21:18:40,991 Stage-3 map = 50%,  reduce = 0%
2016-04-13 21:18:47,024 Stage-3 map = 75%,  reduce = 0%
2016-04-13 21:18:50,043 Stage-3 map = 100%,  reduce = 17%
2016-04-13 21:18:59,091 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604132113_0003
Launching Job 4 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132113_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132113_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132113_0004
2016-04-13 21:19:07,570 Stage-4 map = 0%,  reduce = 0%
2016-04-13 21:19:13,597 Stage-4 map = 100%,  reduce = 0%
2016-04-13 21:19:22,642 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604132113_0004
Launching Job 5 out of 5
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604132113_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604132113_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604132113_0005
2016-04-13 21:19:32,109 Stage-5 map = 0%,  reduce = 0%
2016-04-13 21:19:35,124 Stage-5 map = 100%,  reduce = 0%
2016-04-13 21:19:44,173 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604132113_0005
Loading data to table q3_shipping_priority
10 Rows loaded to q3_shipping_priority
OK
Time taken: 367.638 seconds
