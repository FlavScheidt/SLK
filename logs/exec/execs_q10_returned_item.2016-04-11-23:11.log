Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604112306_377810659.txt
OK
Time taken: 4.779 seconds
OK
Time taken: 0.114 seconds
OK
Time taken: 0.099 seconds
OK
Time taken: 0.091 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q10_returned_item. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 22 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604112306_462852501.txt
OK
Time taken: 3.589 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.011 seconds
OK
Time taken: 0.009 seconds
OK
Time taken: 0.007 seconds
OK
Time taken: 0.426 seconds
OK
Time taken: 0.046 seconds
OK
Time taken: 0.041 seconds
OK
Time taken: 0.058 seconds
OK
Time taken: 0.042 seconds
Total MapReduce jobs = 6
Launching Job 1 out of 6
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604112306_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604112306_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604112306_0001
2016-04-11 23:06:37,990 Stage-1 map = 0%,  reduce = 0%
2016-04-11 23:06:46,049 Stage-1 map = 15%,  reduce = 0%
2016-04-11 23:06:49,090 Stage-1 map = 28%,  reduce = 0%
2016-04-11 23:06:52,126 Stage-1 map = 38%,  reduce = 0%
2016-04-11 23:06:55,159 Stage-1 map = 48%,  reduce = 0%
2016-04-11 23:06:58,192 Stage-1 map = 60%,  reduce = 3%
2016-04-11 23:07:01,228 Stage-1 map = 75%,  reduce = 7%
2016-04-11 23:07:04,261 Stage-1 map = 88%,  reduce = 7%
2016-04-11 23:07:07,295 Stage-1 map = 100%,  reduce = 7%
2016-04-11 23:07:10,329 Stage-1 map = 100%,  reduce = 10%
2016-04-11 23:07:13,364 Stage-1 map = 100%,  reduce = 20%
2016-04-11 23:07:16,397 Stage-1 map = 100%,  reduce = 47%
2016-04-11 23:07:19,435 Stage-1 map = 100%,  reduce = 84%
2016-04-11 23:07:22,473 Stage-1 map = 100%,  reduce = 98%
2016-04-11 23:07:25,509 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604112306_0001
Launching Job 2 out of 6
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604112306_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604112306_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604112306_0002
2016-04-11 23:07:34,127 Stage-2 map = 0%,  reduce = 0%
2016-04-11 23:07:37,150 Stage-2 map = 33%,  reduce = 0%
2016-04-11 23:07:43,200 Stage-2 map = 100%,  reduce = 0%
2016-04-11 23:07:46,228 Stage-2 map = 100%,  reduce = 33%
2016-04-11 23:07:49,255 Stage-2 map = 100%,  reduce = 77%
2016-04-11 23:07:52,286 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604112306_0002
Launching Job 3 out of 6
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604112306_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604112306_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604112306_0003
2016-04-11 23:08:01,959 Stage-3 map = 0%,  reduce = 0%
2016-04-11 23:08:11,009 Stage-3 map = 6%,  reduce = 0%
2016-04-11 23:08:14,028 Stage-3 map = 12%,  reduce = 0%
2016-04-11 23:08:17,048 Stage-3 map = 17%,  reduce = 0%
2016-04-11 23:08:20,089 Stage-3 map = 20%,  reduce = 0%
2016-04-11 23:08:23,116 Stage-3 map = 22%,  reduce = 0%
2016-04-11 23:08:26,143 Stage-3 map = 23%,  reduce = 0%
2016-04-11 23:08:29,170 Stage-3 map = 25%,  reduce = 1%
2016-04-11 23:08:32,205 Stage-3 map = 28%,  reduce = 2%
2016-04-11 23:08:34,227 Stage-3 map = 31%,  reduce = 2%
2016-04-11 23:08:37,255 Stage-3 map = 32%,  reduce = 2%
2016-04-11 23:08:40,282 Stage-3 map = 35%,  reduce = 3%
2016-04-11 23:08:43,307 Stage-3 map = 39%,  reduce = 4%
2016-04-11 23:08:46,331 Stage-3 map = 42%,  reduce = 4%
2016-04-11 23:08:49,355 Stage-3 map = 45%,  reduce = 4%
2016-04-11 23:08:52,380 Stage-3 map = 47%,  reduce = 4%
2016-04-11 23:08:55,405 Stage-3 map = 49%,  reduce = 5%
2016-04-11 23:08:58,428 Stage-3 map = 52%,  reduce = 6%
2016-04-11 23:09:01,451 Stage-3 map = 54%,  reduce = 6%
2016-04-11 23:09:04,474 Stage-3 map = 57%,  reduce = 6%
2016-04-11 23:09:07,496 Stage-3 map = 58%,  reduce = 6%
2016-04-11 23:09:10,517 Stage-3 map = 62%,  reduce = 7%
2016-04-11 23:09:13,540 Stage-3 map = 66%,  reduce = 8%
2016-04-11 23:09:16,561 Stage-3 map = 69%,  reduce = 8%
2016-04-11 23:09:19,583 Stage-3 map = 71%,  reduce = 8%
2016-04-11 23:09:22,604 Stage-3 map = 73%,  reduce = 8%
2016-04-11 23:09:25,625 Stage-3 map = 77%,  reduce = 9%
2016-04-11 23:09:28,648 Stage-3 map = 79%,  reduce = 10%
2016-04-11 23:09:31,671 Stage-3 map = 82%,  reduce = 11%
2016-04-11 23:09:34,691 Stage-3 map = 83%,  reduce = 11%
2016-04-11 23:09:37,711 Stage-3 map = 87%,  reduce = 13%
2016-04-11 23:09:40,733 Stage-3 map = 91%,  reduce = 13%
2016-04-11 23:09:43,754 Stage-3 map = 94%,  reduce = 13%
2016-04-11 23:09:46,775 Stage-3 map = 97%,  reduce = 13%
2016-04-11 23:09:49,795 Stage-3 map = 99%,  reduce = 14%
2016-04-11 23:09:52,815 Stage-3 map = 100%,  reduce = 15%
2016-04-11 23:09:58,853 Stage-3 map = 100%,  reduce = 16%
2016-04-11 23:10:04,889 Stage-3 map = 100%,  reduce = 27%
2016-04-11 23:10:07,910 Stage-3 map = 100%,  reduce = 41%
2016-04-11 23:10:10,931 Stage-3 map = 100%,  reduce = 49%
2016-04-11 23:10:13,952 Stage-3 map = 100%,  reduce = 50%
2016-04-11 23:10:19,990 Stage-3 map = 100%,  reduce = 58%
2016-04-11 23:10:23,011 Stage-3 map = 100%,  reduce = 74%
2016-04-11 23:10:26,034 Stage-3 map = 100%,  reduce = 79%
2016-04-11 23:10:29,055 Stage-3 map = 100%,  reduce = 92%
2016-04-11 23:10:32,077 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604112306_0003
Launching Job 4 out of 6
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604112306_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604112306_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604112306_0004
2016-04-11 23:10:40,610 Stage-4 map = 0%,  reduce = 0%
2016-04-11 23:10:46,641 Stage-4 map = 25%,  reduce = 0%
2016-04-11 23:10:49,660 Stage-4 map = 50%,  reduce = 0%
2016-04-11 23:10:55,693 Stage-4 map = 75%,  reduce = 17%
2016-04-11 23:10:58,711 Stage-4 map = 100%,  reduce = 17%
2016-04-11 23:11:04,744 Stage-4 map = 100%,  reduce = 25%
2016-04-11 23:11:10,778 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604112306_0004
Launching Job 5 out of 6
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604112306_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604112306_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604112306_0005
2016-04-11 23:11:20,216 Stage-5 map = 0%,  reduce = 0%
2016-04-11 23:11:26,247 Stage-5 map = 100%,  reduce = 0%
2016-04-11 23:11:35,308 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604112306_0005
Launching Job 6 out of 6
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604112306_0006, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604112306_0006
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604112306_0006
2016-04-11 23:11:43,695 Stage-6 map = 0%,  reduce = 0%
2016-04-11 23:11:46,711 Stage-6 map = 100%,  reduce = 0%
2016-04-11 23:11:55,761 Stage-6 map = 100%,  reduce = 100%
Ended Job = job_201604112306_0006
Loading data to table q10_returned_item
20 Rows loaded to q10_returned_item
OK
Time taken: 329.32 seconds
