Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604051508_711798475.txt
OK
Time taken: 4.512 seconds
OK
Time taken: 0.089 seconds
OK
Time taken: 0.083 seconds
OK
Time taken: 0.083 seconds
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/hive/warehouse/q10_returned_item. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 25 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:1700)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:1680)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201604051508_820566801.txt
OK
Time taken: 3.846 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.008 seconds
OK
Time taken: 0.009 seconds
OK
Time taken: 0.013 seconds
OK
Time taken: 0.493 seconds
OK
Time taken: 0.039 seconds
OK
Time taken: 0.041 seconds
OK
Time taken: 0.041 seconds
OK
Time taken: 0.033 seconds
Total MapReduce jobs = 6
Launching Job 1 out of 6
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604051508_0001, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604051508_0001
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604051508_0001
2016-04-05 15:08:47,280 Stage-1 map = 0%,  reduce = 0%
2016-04-05 15:08:56,346 Stage-1 map = 14%,  reduce = 0%
2016-04-05 15:08:59,383 Stage-1 map = 28%,  reduce = 0%
2016-04-05 15:09:02,421 Stage-1 map = 39%,  reduce = 0%
2016-04-05 15:09:05,456 Stage-1 map = 47%,  reduce = 0%
2016-04-05 15:09:08,491 Stage-1 map = 57%,  reduce = 0%
2016-04-05 15:09:11,523 Stage-1 map = 67%,  reduce = 7%
2016-04-05 15:09:14,556 Stage-1 map = 78%,  reduce = 7%
2016-04-05 15:09:17,589 Stage-1 map = 93%,  reduce = 7%
2016-04-05 15:09:20,623 Stage-1 map = 100%,  reduce = 7%
2016-04-05 15:09:26,686 Stage-1 map = 100%,  reduce = 27%
2016-04-05 15:09:32,753 Stage-1 map = 100%,  reduce = 86%
2016-04-05 15:09:35,792 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201604051508_0001
Launching Job 2 out of 6
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604051508_0002, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604051508_0002
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604051508_0002
2016-04-05 15:09:44,468 Stage-2 map = 0%,  reduce = 0%
2016-04-05 15:09:47,491 Stage-2 map = 33%,  reduce = 0%
2016-04-05 15:09:50,519 Stage-2 map = 67%,  reduce = 0%
2016-04-05 15:09:53,548 Stage-2 map = 100%,  reduce = 0%
2016-04-05 15:09:56,575 Stage-2 map = 100%,  reduce = 33%
2016-04-05 15:09:59,602 Stage-2 map = 100%,  reduce = 79%
2016-04-05 15:10:02,632 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_201604051508_0002
Launching Job 3 out of 6
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604051508_0003, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604051508_0003
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604051508_0003
2016-04-05 15:10:11,523 Stage-3 map = 0%,  reduce = 0%
2016-04-05 15:10:20,574 Stage-3 map = 6%,  reduce = 0%
2016-04-05 15:10:23,594 Stage-3 map = 11%,  reduce = 0%
2016-04-05 15:10:26,614 Stage-3 map = 16%,  reduce = 0%
2016-04-05 15:10:29,638 Stage-3 map = 19%,  reduce = 0%
2016-04-05 15:10:32,681 Stage-3 map = 22%,  reduce = 0%
2016-04-05 15:10:35,710 Stage-3 map = 23%,  reduce = 0%
2016-04-05 15:10:38,739 Stage-3 map = 26%,  reduce = 1%
2016-04-05 15:10:41,766 Stage-3 map = 28%,  reduce = 2%
2016-04-05 15:10:44,796 Stage-3 map = 31%,  reduce = 2%
2016-04-05 15:10:47,827 Stage-3 map = 32%,  reduce = 2%
2016-04-05 15:10:50,856 Stage-3 map = 36%,  reduce = 3%
2016-04-05 15:10:53,888 Stage-3 map = 39%,  reduce = 4%
2016-04-05 15:10:56,913 Stage-3 map = 42%,  reduce = 4%
2016-04-05 15:10:59,939 Stage-3 map = 45%,  reduce = 4%
2016-04-05 15:11:02,964 Stage-3 map = 48%,  reduce = 4%
2016-04-05 15:11:05,988 Stage-3 map = 50%,  reduce = 4%
2016-04-05 15:11:08,005 Stage-3 map = 50%,  reduce = 5%
2016-04-05 15:11:09,016 Stage-3 map = 51%,  reduce = 6%
2016-04-05 15:11:11,033 Stage-3 map = 52%,  reduce = 7%
2016-04-05 15:11:12,044 Stage-3 map = 53%,  reduce = 8%
2016-04-05 15:11:14,061 Stage-3 map = 54%,  reduce = 8%
2016-04-05 15:11:15,072 Stage-3 map = 55%,  reduce = 8%
2016-04-05 15:11:17,087 Stage-3 map = 57%,  reduce = 8%
2016-04-05 15:11:18,097 Stage-3 map = 59%,  reduce = 8%
2016-04-05 15:11:20,113 Stage-3 map = 60%,  reduce = 8%
2016-04-05 15:11:21,124 Stage-3 map = 62%,  reduce = 8%
2016-04-05 15:11:23,139 Stage-3 map = 65%,  reduce = 8%
2016-04-05 15:11:24,148 Stage-3 map = 67%,  reduce = 8%
2016-04-05 15:11:26,163 Stage-3 map = 69%,  reduce = 8%
2016-04-05 15:11:27,174 Stage-3 map = 70%,  reduce = 8%
2016-04-05 15:11:29,190 Stage-3 map = 72%,  reduce = 8%
2016-04-05 15:11:30,199 Stage-3 map = 73%,  reduce = 8%
2016-04-05 15:11:32,215 Stage-3 map = 74%,  reduce = 8%
2016-04-05 15:11:36,241 Stage-3 map = 76%,  reduce = 9%
2016-04-05 15:11:38,256 Stage-3 map = 77%,  reduce = 10%
2016-04-05 15:11:39,266 Stage-3 map = 78%,  reduce = 10%
2016-04-05 15:11:41,282 Stage-3 map = 79%,  reduce = 11%
2016-04-05 15:11:42,291 Stage-3 map = 81%,  reduce = 12%
2016-04-05 15:11:44,308 Stage-3 map = 83%,  reduce = 12%
2016-04-05 15:11:45,318 Stage-3 map = 84%,  reduce = 12%
2016-04-05 15:11:47,333 Stage-3 map = 85%,  reduce = 12%
2016-04-05 15:11:48,343 Stage-3 map = 87%,  reduce = 12%
2016-04-05 15:11:50,358 Stage-3 map = 89%,  reduce = 12%
2016-04-05 15:11:51,368 Stage-3 map = 90%,  reduce = 12%
2016-04-05 15:11:53,383 Stage-3 map = 93%,  reduce = 12%
2016-04-05 15:11:54,392 Stage-3 map = 94%,  reduce = 12%
2016-04-05 15:11:56,407 Stage-3 map = 95%,  reduce = 12%
2016-04-05 15:11:57,417 Stage-3 map = 96%,  reduce = 13%
2016-04-05 15:11:59,433 Stage-3 map = 97%,  reduce = 13%
2016-04-05 15:12:00,442 Stage-3 map = 98%,  reduce = 13%
2016-04-05 15:12:03,463 Stage-3 map = 99%,  reduce = 14%
2016-04-05 15:12:05,480 Stage-3 map = 100%,  reduce = 15%
2016-04-05 15:12:11,518 Stage-3 map = 100%,  reduce = 16%
2016-04-05 15:12:14,538 Stage-3 map = 100%,  reduce = 24%
2016-04-05 15:12:17,558 Stage-3 map = 100%,  reduce = 36%
2016-04-05 15:12:20,581 Stage-3 map = 100%,  reduce = 46%
2016-04-05 15:12:23,603 Stage-3 map = 100%,  reduce = 50%
2016-04-05 15:12:26,623 Stage-3 map = 100%,  reduce = 54%
2016-04-05 15:12:29,645 Stage-3 map = 100%,  reduce = 59%
2016-04-05 15:12:32,665 Stage-3 map = 100%,  reduce = 71%
2016-04-05 15:12:35,686 Stage-3 map = 100%,  reduce = 83%
2016-04-05 15:12:38,707 Stage-3 map = 100%,  reduce = 94%
2016-04-05 15:12:41,729 Stage-3 map = 100%,  reduce = 97%
2016-04-05 15:12:44,750 Stage-3 map = 100%,  reduce = 100%
Ended Job = job_201604051508_0003
Launching Job 4 out of 6
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604051508_0004, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604051508_0004
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604051508_0004
2016-04-05 15:12:53,235 Stage-4 map = 0%,  reduce = 0%
2016-04-05 15:13:02,280 Stage-4 map = 25%,  reduce = 0%
2016-04-05 15:13:03,288 Stage-4 map = 50%,  reduce = 0%
2016-04-05 15:13:11,331 Stage-4 map = 75%,  reduce = 17%
2016-04-05 15:13:12,340 Stage-4 map = 100%,  reduce = 17%
2016-04-05 15:13:20,383 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201604051508_0004
Launching Job 5 out of 6
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604051508_0005, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604051508_0005
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604051508_0005
2016-04-05 15:13:29,851 Stage-5 map = 0%,  reduce = 0%
2016-04-05 15:13:35,881 Stage-5 map = 100%,  reduce = 0%
2016-04-05 15:13:44,928 Stage-5 map = 100%,  reduce = 100%
Ended Job = job_201604051508_0005
Launching Job 6 out of 6
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201604051508_0006, Tracking URL = http://belona.c3local:50030/jobdetails.jsp?jobid=job_201604051508_0006
Kill Command = /home/hadoop/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=belona.c3local:9001 -kill job_201604051508_0006
2016-04-05 15:13:53,315 Stage-6 map = 0%,  reduce = 0%
2016-04-05 15:13:56,332 Stage-6 map = 100%,  reduce = 0%
2016-04-05 15:14:05,382 Stage-6 map = 100%,  reduce = 100%
Ended Job = job_201604051508_0006
Loading data to table q10_returned_item
20 Rows loaded to q10_returned_item
OK
Time taken: 328.018 seconds
